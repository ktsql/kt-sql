# check list

## 测试说明

KtSQL虽然采用MySQL协议作为其通信协议，但是并没有完全支持MySQL的全部功能

## 测试方法

- 使用jdbc调用mysql driver访问
- http://www.tpc.org/
- 使用应用client访问

## 测试环境搭建

以下是从理论上对KtSQL各节点进行性能估算，并预估搭建集群需要的规模。

### 前端节点

KtSQL前端节点，单核的TPS为200，在8核的机器上，TPS达到1500，16核TPS达3000，
32核TPS达到6000，依据主流的服务器搭配，32核的服务器配128G内存，
32核128G内存的配置可实现千万级数据的内存计算，单机的TPS为5000左右。

参考salesforce 2013年的服务端数据，其峰值每秒数据库的tps达到2.4万，
以salesforce 2013年约30亿美金的营收规模估算其付费用户规模为300万，
考虑到有部分用户为试用型的用户，salesforce的用户规模可以估算为400万，
要支撑同样规模的用户数，KtSQL的前端节点，应该要达到10台以上的规模。

以中国互联网的双十一活动为例，2017年秒级交易创建峰值达到了32.5万，
这个业务规模是salesforce的10倍，这需要KtSQL的前端节点达到100台以上规模。

### HBase节点

以32核128G配置的HBase节点性能评估，单机节点可达到过万的TPS，如果要配合KtSQL前端10台节点，
估算TPS为5万，则HBase的节点规模建议为5台以上，同时要部署两台hbase master节点搭建集群。
考虑到单机节点存储建议不超过10T的存储量，集群支撑的数据规模上限在50T，集群支撑的最大存储数据规模可达百亿级。

考虑到HBase数据的读性能<写性能，读性能scan为最耗时的操作，在全读的情况下，
单节点可以每秒读取1G以上数据，5节点可满足5G的数据，完成千万级别数据规模的秒级扫描操作，
考虑到百亿级别数据的冷热比例，秒级完成1/1000整体规模的数据处理是合理的。

这里是网易云对HBase的性能测试报告
https://www.cnblogs.com/163yun/p/9661570.html

### Hadoop节点

hadoop节点用于为hbase提供持久化的存储，所需节点满足hbase的存储规模*3即可，按单机24T*6配置

### Tephra节点

Tephra是单机节点，并通过zookeeper的支持，实现了3节点的高可用，所以搭建Tephra需要3台机器，
为保证Tephra的性能，可考虑采用高配的服务器，如64核256G内存

### zookeeper节点

Zookeeper为HBase和Tephra提供高可用服务，建议3台机器

### 整体规模

- 前端节点10台服务器（stable）
- 7台HBase（1.3.x）
- 6台Hadoop构建hdfs（2.7.x）
- 3台Tephra（0.15+）
- 3台zookeeper（Version 3.4.3 through 3.4.5）
- 2台haproxy用于前端节点负载均衡（stable）

## 测试结果

